Our approach to this problem was to use a pre-trained model, namely the Efficient Net B6 model available on PyTorch to transform the features. In particular, we removed the last layer of this Neural net and used the outputted features as input for our own model.
Our model is composed of a linear layer which sends features to two convolution layers, finally completed by two more linear layers. Between all these layers, we used Max pooling and dropouts to reduce dimensions of the feature tensors. Non linearities were introduced with a Leaky Rectified Linear Unit.
For the loss, we used the Triplet Margin Loss, which given an anchor, a positive and a negative tensor of transformed images, checks that the negative tensor is further to the anchor than the positive tensor. Hence our CNN aims at transforming the image features to maximise the Triplet margin loss. This way, given a triplet (A, B, C), we transform the image features and compute the Euclidean distances d(A, B) and d(A, C) and decide which image is closer to A.