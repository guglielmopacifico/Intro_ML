{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# from sklearn.model_selection import (GridSearchCV, cross_val_score, KFold)\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_features.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "test_data = pd.read_csv('test_features.csv')\n",
    "\n",
    "# dataframe for the solution\n",
    "df = pd.DataFrame({'pid': test_data.iloc[0::12, 0].values})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_time_features(data, n_samples):\n",
    "#     x = []\n",
    "#     features = [np.nanmedian, np.nanmean, np.nanvar, np.nanmin,\n",
    "#            np.nanmax]\n",
    "#     for index in range(int(data.shape[0] / n_samples)):\n",
    "#         assert data[n_samples * index, 0] == data[n_samples * (index + 1) - 1, 0], \\\n",
    "#         'Ids are {}, {}'.format(data[n_samples * index, 0], data[n_samples * (index + 1) - 1, 0])\n",
    "#         patient_data = data[n_samples * index:n_samples * (index + 1), 2:]\n",
    "#         feature_values = np.empty((len(features), data[:, 2:].shape[1]))\n",
    "#         for i, feature in enumerate(features):\n",
    "#             feature_values[i] = feature(patient_data, axis=0)\n",
    "#         x.append(feature_values.ravel())\n",
    "#     return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = calculate_time_features(train_data.to_numpy(), 12)\n",
    "# x_test = calculate_time_features(test_data.to_numpy(), 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_formatting(data, n_samples):\n",
    "    x = []\n",
    "    for index in range(int(data.shape[0] / n_samples)):\n",
    "        patient_data = data[n_samples * index:n_samples * (index + 1), 2:]\n",
    "        x.append(patient_data.flatten())\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = feature_formatting(train_data.to_numpy(), 12)\n",
    "x_test = feature_formatting(test_data.to_numpy(), 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3_labels = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "y_train = labels[t3_labels].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.6068055282408376\n",
      "Training score: 0.7413608170738564\n",
      "Training score: 0.531351947234971\n",
      "Training score: 0.734737589026784\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Mean R2:\t 0.6535639703941123\n",
      "Score:\t\t 0.8267819851970561\n",
      "----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mean_r2 = 0\n",
    "score = 0\n",
    "for i, label in enumerate(t3_labels):\n",
    "    method = HistGradientBoostingRegressor(max_depth=15)\n",
    "    method.fit(x_train, y_train[:, i])\n",
    "    predictions = method.predict(x_test)\n",
    "    print(\"Training score:\", metrics.r2_score(y_train[:, i], method.predict(x_train)))\n",
    "    df[label] = predictions\n",
    "    mean_r2 += metrics.r2_score(y_train[:, i], method.predict(x_train))\n",
    "    score += 0.5 + 0.5*np.maximum(0, metrics.r2_score(y_train[:, i], method.predict(x_train)))\n",
    "print(\"\\n----------------------------------------------------------------------------------\")\n",
    "print(\"Mean R2:\\t\", mean_r2/4)\n",
    "print(\"Score:\\t\\t\", score/4)\n",
    "print(\"----------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.5751978246041309\n",
      "Training score: 0.7227957753930083\n",
      "Training score: 0.5221852247854422\n",
      "Training score: 0.7601115333363111\n",
      "\n",
      "----------------------------------------------------------------------------------\n",
      "Mean R2:\t 0.6450725895297231\n",
      "Score:\t\t 1.6493182799619175\n",
      "----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# mean_r2 = 0\n",
    "# score = 0\n",
    "\n",
    "# for i, label in enumerate(t3_labels):\n",
    "#     pipeline = make_pipeline(\n",
    "#                         #SimpleImputer(strategy='median'),\n",
    "#                         #StandardScaler(),\n",
    "#                         HistGradientBoostingRegressor(max_depth=15))\n",
    "#     pipeline = pipeline.fit(x_train, y_train[:, i])\n",
    "#     predictions = pipeline.predict(x_test)\n",
    "#     print(\"Training score:\", metrics.r2_score(y_train[:, i], pipeline.predict(x_train)))\n",
    "#     df[label] = predictions\n",
    "#     mean_r2 += metrics.r2_score(y_train[:, i], pipeline.predict(x_train))\n",
    "#     score += 0.5 + 0.5*np.maximum(0, metrics.r2_score(y_train[:, i], pipeline.predict(x_train)))\n",
    "\n",
    "# print(\"\\n----------------------------------------------------------------------------------\")\n",
    "# print(\"Mean R2:\\t\", mean_r2/4)\n",
    "# print(\"Score:\\t\\t\", score/4)\n",
    "# print(\"----------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('predict ion.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7cf9b0d7ec11fce6e1e79b6ce3b4dc811df290f7a929d0498e5879122e6ba4f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
